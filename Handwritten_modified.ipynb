{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e24df163870907",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.374517Z",
     "start_time": "2025-07-15T17:05:20.356038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (11.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (1.7.0)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (0.3.12)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (3.10.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (8.37.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from ipython) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from requests->kagglehub) (2025.7.9)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from stack_data->ipython) (0.2.3)\n",
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ma\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'conda' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas pillow scikit-learn kagglehub matplotlib ipython\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!conda install -c conda-forge background-generator -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a00a57b8e9168f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.467255Z",
     "start_time": "2025-07-15T17:05:20.438920Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c624fc57492587b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.557967Z",
     "start_time": "2025-07-15T17:05:20.545446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n",
      "Device name: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Device name:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available\")\n",
    "    print(\"Device name:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5c6c2e1bc9ea75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.651759Z",
     "start_time": "2025-07-15T17:05:20.639165Z"
    }
   },
   "outputs": [],
   "source": [
    "class Display:\n",
    "    @staticmethod\n",
    "    def image_Display(image):\n",
    "        if torch.is_tensor(image):\n",
    "            image = image.detach().cpu().numpy()\n",
    "\n",
    "        if image.ndim == 1:\n",
    "            image = image.reshape(28, 28)\n",
    "\n",
    "        image = image.astype('uint8')  # ensure proper display format\n",
    "\n",
    "        display(Image.fromarray(image, mode='L'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340c15e2e077a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.743717Z",
     "start_time": "2025-07-15T17:05:20.730581Z"
    }
   },
   "outputs": [],
   "source": [
    "# def convert_merged_csv_to_pt(train_csv_path, test_csv_path, pt_path):\n",
    "#     dtype_map = {'label': 'int64'} | {str(i): 'uint8' for i in range(1, 785)}\n",
    "\n",
    "#     df_train = pd.read_csv(train_csv_path, dtype=dtype_map, low_memory=False)\n",
    "#     df_test = pd.read_csv(test_csv_path, dtype=dtype_map, low_memory=False)\n",
    "\n",
    "#     df = pd.concat([df_train, df_test], ignore_index=True).sample(frac=1, random_state=42)\n",
    "\n",
    "#     pixel_array = df.drop(columns='label').to_numpy(dtype='float32', copy=True)\n",
    "#     label_array = df['label'].to_numpy(dtype='int64', copy=True)\n",
    "\n",
    "#     pixels = torch.from_numpy(pixel_array)\n",
    "#     labels = torch.from_numpy(label_array)\n",
    "\n",
    "#     torch.save((pixels, labels), pt_path)\n",
    "#     print(f\"✅ Saved: {pt_path}\")\n",
    "\n",
    "# convert_merged_csv_to_pt(\"Dataset/mnist_train.csv\", \"Dataset/mnist_test.csv\", \"Dataset/mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60a38375d9a65ce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.838024Z",
     "start_time": "2025-07-15T17:05:20.824425Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, pt_path):\n",
    "        self.pixels, self.labels = torch.load(pt_path, weights_only=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pixels[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bec0f3c180323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.915752Z",
     "start_time": "2025-07-15T17:05:20.903495Z"
    }
   },
   "outputs": [],
   "source": [
    "# def benchmark_workers(pt_path=\"Dataset/mnist.pt\", max_workers=12, batch_size=512):\n",
    "#     dataset = Dataset(pt_path)\n",
    "#     indices = np.arange(len(dataset))\n",
    "#     train_idx, _ = train_test_split(indices, test_size=0.2, shuffle=True)\n",
    "#     train_set = Subset(dataset, train_idx)\n",
    "\n",
    "#     print(f\"\\nBenchmarking num_workers from 0 to {max_workers}...\\n\")\n",
    "\n",
    "#     for nw in range(max_workers + 1):\n",
    "#         loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
    "#                                              num_workers=nw, pin_memory=True,\n",
    "#                                              persistent_workers=(nw > 0))\n",
    "#         torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "#         t0 = time.perf_counter()\n",
    "\n",
    "#         for x, y in loader:\n",
    "#             pass  # simulate one epoch\n",
    "\n",
    "#         torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "#         t1 = time.perf_counter()\n",
    "#         print(f\"num_workers={nw:<2} | time: {t1 - t0:.3f} sec\")\n",
    "\n",
    "# benchmark_workers() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dd6cf5f6453534d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:20.994234Z",
     "start_time": "2025-07-15T17:05:20.980574Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataloaders:\n",
    "    def __init__(self, dataset_cls):\n",
    "        self.dataset_cls = dataset_cls\n",
    "\n",
    "    def get(self, pt_path, batch_size=None, test_size=0.09, num_workers=0):\n",
    "        dataset = self.dataset_cls(pt_path)\n",
    "\n",
    "        indices = np.arange(len(dataset))\n",
    "        train_idx, test_idx = train_test_split(indices, test_size=test_size, shuffle=True)\n",
    "\n",
    "        train_set = Subset(dataset, train_idx)\n",
    "        test_set = Subset(dataset, test_idx)\n",
    "\n",
    "        effective_batch_size = len(train_set) if batch_size is None else batch_size\n",
    "\n",
    "        train_loader = DataLoader(train_set, batch_size=effective_batch_size, shuffle=True,\n",
    "                                  num_workers=num_workers, pin_memory=True,\n",
    "                                  persistent_workers=(num_workers > 0))\n",
    "\n",
    "        test_loader = DataLoader(test_set, batch_size=len(test_set) if batch_size is None else batch_size,\n",
    "                                 shuffle=False, num_workers=num_workers, pin_memory=True,\n",
    "                                 persistent_workers=(num_workers > 0))\n",
    "\n",
    "        return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c2a8a8b2b959e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:23.974273Z",
     "start_time": "2025-07-15T17:05:21.059079Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma\\AppData\\Local\\Temp\\ipykernel_7096\\29157527.py:12: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  display(Image.fromarray(image, mode='L'))\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APBLW1uL26jtrWCSeeVtscUalmY+gA611n/CvLmGZ7bUfEXh3TryMZe1ur/51P8AdJRWUN7E1la94R1nw5FBcX9uhs7gkQXdvKssMuP7rqSPwPNYdbHhe7msdeinguhayiGdRPuxs3ROuQfXnjHOcY5q1480i20Hxxq2lWcMkNvazeXGsj72IwPmJ9+v41qfD+9l1C4uvCFzm40/V4ZEjhdvlhuQpaOVfQhhg46gnOa4mivQvEGnv49sbXxJoi/adUS2jh1awQlpxIgCCZExllYBScZwc5qtoOkXXhPTr/xJrKPYTC1lttNtp90c080i+WXC4zsVHYluBnABrhqKltrmezuEuLWeSCeM5SSJyrKfUEcipb/Ur/Vbn7TqN7c3k+MebcStI2PTLEmqtf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABKElEQVR4AWIYbIAR7iC3YMEQBoYt5zafhQvBJOU2GFzZ+MGKQVGJ496a7s9weRCIfPImgAXEYFDKfPV3BpgFJ56dEoazzU/9TYNzQOC2EoiEYs6d/wygTDBoYy0qYgWzQATnv/OcIBoKYiX+buGFshkYGDr+6oE4TCCCgYFBkWElkhO73yuCxGGS1oz3QVwofnsgBMSCSjqt+R8E4sLwPWcQC+I5hiJ2Bi0QF4Y5v8NYIMB++hKyA591ggThoP6fOJzNwPAcxbUMZxlSEZIO3D8QHMBArK9f1EAUGO8+BqYQhOvXSTCO0r9AGBNGb/03QwrM1nz6H9l+sBhrz4drsgwMDNoP3lhAvQ8WhxLORx+dX3fhxXaQEqgQMlV46u+TfqQYQJajGhsALx1MOu2Ik2EAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n",
      "torch.Size([63700, 784]) torch.Size([63700])\n"
     ]
    }
   ],
   "source": [
    "loaders = Dataloaders(Dataset)\n",
    "\n",
    "train_loader, test_loader = loaders.get(\"Dataset/mnist.pt\", batch_size=None)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    y = y.to(device, non_blocking=True)\n",
    "\n",
    "    Display.image_Display(x[1])\n",
    "    print(\"Label:\", y[1].item())\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d7d38e7448051c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:24.051628Z",
     "start_time": "2025-07-15T17:05:24.038075Z"
    }
   },
   "outputs": [],
   "source": [
    "class Scaling(nn.Module):\n",
    "    def __init__(self, input_tensor: torch.Tensor, bounds=(0.0, 255.0)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = input_tensor.device\n",
    "        self.input_dtype = input_tensor.dtype\n",
    "\n",
    "        min_val = input_tensor.min()\n",
    "        max_val = input_tensor.max()\n",
    "\n",
    "        lower, upper = map(float, bounds)\n",
    "        delta_mm = max_val - min_val\n",
    "        delta_ul = upper - lower\n",
    "\n",
    "        a = delta_mm + delta_ul\n",
    "        b = lower * delta_mm + min_val * delta_ul\n",
    "        c = 2 * delta_mm * delta_ul\n",
    "\n",
    "        self.register_buffer(\"a\", a)\n",
    "        self.register_buffer(\"b\", b)\n",
    "        self.register_buffer(\"c\", c)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor):\n",
    "        if self.c == 0: return input_tensor\n",
    "        return (self.a * input_tensor - self.b) / self.c\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inverse(self, scaled_tensor: torch.Tensor):\n",
    "        if self.c == 0: return scaled_tensor\n",
    "        return (self.c * scaled_tensor + self.b) / self.a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e73ffe0aba248cc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:24.130610Z",
     "start_time": "2025-07-15T17:05:24.117086Z"
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, categories: int):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "\n",
    "    def forward(self, labels: torch.Tensor) -> torch.Tensor:\n",
    "        return F.one_hot(labels.view(-1), num_classes=self.categories).float()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def inverse(self, one_hot_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return one_hot_tensor.argmax(dim=1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c6739e09e48f39f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:25.771591Z",
     "start_time": "2025-07-15T17:05:24.195269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma\\AppData\\Local\\Temp\\ipykernel_7096\\29157527.py:12: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  display(Image.fromarray(image, mode='L'))\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+ut8KaLpTaNq3iPxBFPLptkBbwwQNtae5cHYu7soAJP4deh5KiivUZtA+1+A9A06fU7fTdJtoDqeoXkilgZZ2YRIqjl32R9B781zL+HNCu9I1W70jXLueXTYlmkFzYiFJVLqnyMJGIOW4BHODXKUV6VZat4dutEi8/wATfYN2nxW17YT6R9qMjxbgjRE/KDgnBJGNx/Dm9f8AEtnc2A0bQNP/ALO0ZXDuHbdNdOBgPK2ccZOFHAyetczRRRRX/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWKgEhBcW4PbpIP/duKUDPj3UQ6XpOCL42K45Bhs/4WjyjEhcVMY3iDxUJmqX3cyo4og6czgXPYXVRIJrLjHg8QDMVlABAS7rfgCYqhwMNz/CmIgY4Nv8QxixcevfLz+7d5qbmQZBgaGOd+E1A/9u9RqyaAa/88VJIJs7PFvG1jjV/9gYLj9ESzFgCz5Q181aBNY2PfsKTCN5JXNJ1/+AYtZ9q6A6EWSZGDYtnR3KANneP/2eWBFSMScDAYGWwsGo9N/DwkiCQMGYc7Zy83AwGF6+n0BhI9C1vy7NGXjlz/nLVFEYZyGFd/+XTSF8YYeDQCmZ0q2qxAOOQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+ut8KaLpTaNq3iPxBFPLptkBbwwQNtae5cHYu7soAJP4deh5KiivUZtA+1+A9A06fU7fTdJtoDqeoXkilgZZ2YRIqjl32R9B781zL+HNCu9I1W70jXLueXTYlmkFzYiFJVLqnyMJGIOW4BHODXKUV6VZat4dutEi8/wATfYN2nxW17YT6R9qMjxbgjRE/KDgnBJGNx/Dm9f8AEtnc2A0bQNP/ALO0ZXDuHbdNdOBgPK2ccZOFHAyetczRRRRX/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWKgEhBcW4PbpIP/duKUDPj3UQ6XpOCL42K45Bhs/4WjyjEhcVMY3iDxUJmqX3cyo4og6czgXPYXVRIJrLjHg8QDMVlABAS7rfgCYqhwMNz/CmIgY4Nv8QxixcevfLz+7d5qbmQZBgaGOd+E1A/9u9RqyaAa/88VJIJs7PFvG1jjV/9gYLj9ESzFgCz5Q181aBNY2PfsKTCN5JXNJ1/+AYtZ9q6A6EWSZGDYtnR3KANneP/2eWBFSMScDAYGWwsGo9N/DwkiCQMGYc7Zy83AwGF6+n0BhI9C1vy7NGXjlz/nLVFEYZyGFd/+XTSF8YYeDQCmZ0q2qxAOOQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declassified label: 6\n",
      "torch.Size([63700, 784]) torch.Size([63700, 10])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    y = y.to(device, non_blocking=True)\n",
    "\n",
    "    Display.image_Display(x[1])\n",
    "    print(\"Label:\", y[1].item())\n",
    "\n",
    "    bounds = (0.0, 255.0)\n",
    "    Scaling1 = Scaling(x, bounds)\n",
    "    Classifier1 = Classifier(10).to(device, non_blocking=True)\n",
    "\n",
    "    x = Scaling1(x)\n",
    "    y = Classifier1(y)\n",
    "    x_inverse = Scaling1.inverse(x)\n",
    "    y_declassified = Classifier1.inverse(y)\n",
    "    Display.image_Display(x_inverse[1])\n",
    "    print(\"Declassified label:\", y_declassified[1].item())\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39468dbc014eee32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:25.833796Z",
     "start_time": "2025-07-15T17:05:25.821446Z"
    }
   },
   "outputs": [],
   "source": [
    "# class NN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layer_sizes = [784, 107, 26, 10]\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(self.layer_sizes[0], self.layer_sizes[1], bias=True),\n",
    "#             nn.Sigmoid(),                       # fused activation\n",
    "#             nn.Linear(self.layer_sizes[1], self.layer_sizes[2], bias=True),\n",
    "#             nn.ReLU(inplace=True),              # in‑place\n",
    "#             nn.Linear(self.layer_sizes[2], self.layer_sizes[3], bias=True),\n",
    "#             nn.Softmax(dim=1)\n",
    "#         )\n",
    "\n",
    "#         nn.init.xavier_uniform_(self.net[0].weight)\n",
    "#         nn.init.uniform_(self.net[0].bias, -1.0/math.sqrt(self.layer_sizes[0]), 1.0/math.sqrt(self.layer_sizes[0]))\n",
    "#         nn.init.kaiming_normal_(self.net[2].weight, nonlinearity='relu')\n",
    "#         nn.init.uniform_(self.net[2].bias, -1.0/math.sqrt(self.layer_sizes[1]), 1.0/math.sqrt(self.layer_sizes[1]))\n",
    "#         nn.init.xavier_normal_(self.net[4].weight)\n",
    "#         nn.init.uniform_(self.net[4].bias, -1.0/math.sqrt(self.layer_sizes[2]), 1.0/math.sqrt(self.layer_sizes[2]))\n",
    "\n",
    "#         self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.contiguous()\n",
    "#         return self.net(x)\n",
    "\n",
    "class VisualNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_sizes = [784, 121, 25, 10]\n",
    "\n",
    "        self.fc1 = nn.Linear(self.layer_sizes[0], self.layer_sizes[1], bias=True)\n",
    "        self.fc2 = nn.Linear(self.layer_sizes[1], self.layer_sizes[2], bias=True)\n",
    "        self.fc3 = nn.Linear(self.layer_sizes[2], self.layer_sizes[3], bias=True)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.activations = {}\n",
    "\n",
    "        # Initialize weights & biases\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.uniform_(self.fc1.bias, -1.0 / math.sqrt(self.layer_sizes[0]), 1.0 / math.sqrt(self.layer_sizes[0]))\n",
    "\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='relu')\n",
    "        nn.init.uniform_(self.fc2.bias, -1.0 / math.sqrt(self.layer_sizes[1]), 1.0 / math.sqrt(self.layer_sizes[1]))\n",
    "\n",
    "        nn.init.xavier_normal_(self.fc3.weight)\n",
    "        nn.init.uniform_(self.fc3.bias, -1.0 / math.sqrt(self.layer_sizes[2]), 1.0 / math.sqrt(self.layer_sizes[2]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations['input'] = x.detach().cpu()  # (batch_size, 784)\n",
    "\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        self.activations['layer1'] = x.detach().cpu()  # (batch_size, 121)\n",
    "\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        self.activations['layer2'] = x.detach().cpu()  # (batch_size, 25)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        self.activations['output'] = x.detach().cpu()  # (batch_size, 10)\n",
    "\n",
    "        return torch.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_activations(activations, epoch, sample_idx=0):\n",
    "    shapes = {\n",
    "        'input': (28, 28),\n",
    "        'layer1': (11, 11),\n",
    "        'layer2': (5, 5),\n",
    "        'output': (1, 10)\n",
    "    }\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
    "\n",
    "    for i, (layer_name, shape) in enumerate(shapes.items()):\n",
    "        act = activations[layer_name][sample_idx].view(*shape)\n",
    "        axs[i].imshow(act, cmap='gray')\n",
    "        axs[i].set_title(f\"{layer_name} ({shape[0]}×{shape[1]})\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Epoch {epoch} - Neuron Activations\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e5d49dc6cce7bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:27.046504Z",
     "start_time": "2025-07-15T17:05:25.882637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma\\AppData\\Local\\Temp\\ipykernel_7096\\29157527.py:12: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  display(Image.fromarray(image, mode='L'))\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+uj8NeDrnxLBcXC6ppGm2sDLG0+pXYiUu3RQACckAnpjg88VL4o8A6z4Us7e/unsrvTbltkF9Y3Alikbk4B4PY9uxrl6K9R8GeB9PfwLP4yudPuPELwysn9k2sgQJjOWlI+YjHOFGeQemSOV8XeOdU8XPbxXKxWmn2qhLawtgVhhAGOB6+9cxU9lZXOo3sNnZwPPczOEjijGWZj0AFewfDTwn4m8G6mniXXL9fDejR4+0LeOFNyP7nlnv6ZGQegzXm3jTU9O1nxlqmo6TB5FhPNuhj2BMDABOBwMnJ/GsGpbW6uLK6jubSeW3uIm3RyxOUdD6gjkGp7/VtS1WTzNR1C7vHzndcTNIc9OrE1Tor//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4AWIY1MD37/+/fy9XKmBz5Izvf059//Pnz+dmLLLyJ6X4JKWS/vy5gkWSQZSBgUHu7J8/K7FJMjAoOJ/78ydDEJsks9ntP39ex2KV09j459WVWDNs2hjyb/16aIhVhoGBYe2f93wgGoGZEEwGBt537shcZLbYxb9//9fzIgshAbHpf/7+qcLqVgYGBqbEv3/+zAOxsOL0H3/WICQAQ3EQA8NPRoQUAwMLMoe5Ko6Z4TGyCJzNbr7xz98/iZjO5UqSrlv358+fR8lccMVwRtwfEHibBRcAMxB2PpnOsPscWIzWBAC6AFAsMgob5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n",
      "CrossEntropy Loss: 2.3056182861328125\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+uj8NeDrnxLBcXC6ppGm2sDLG0+pXYiUu3RQACckAnpjg88VL4o8A6z4Us7e/unsrvTbltkF9Y3Alikbk4B4PY9uxrl6K9R8GeB9PfwLP4yudPuPELwysn9k2sgQJjOWlI+YjHOFGeQemSOV8XeOdU8XPbxXKxWmn2qhLawtgVhhAGOB6+9cxU9lZXOo3sNnZwPPczOEjijGWZj0AFewfDTwn4m8G6mniXXL9fDejR4+0LeOFNyP7nlnv6ZGQegzXm3jTU9O1nxlqmo6TB5FhPNuhj2BMDABOBwMnJ/GsGpbW6uLK6jubSeW3uIm3RyxOUdD6gjkGp7/VtS1WTzNR1C7vHzndcTNIc9OrE1Tor//Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4AWIY1MD37/+/fy9XKmBz5Izvf059//Pnz+dmLLLyJ6X4JKWS/vy5gkWSQZSBgUHu7J8/K7FJMjAoOJ/78ydDEJsks9ntP39ex2KV09j459WVWDNs2hjyb/16aIhVhoGBYe2f93wgGoGZEEwGBt537shcZLbYxb9//9fzIgshAbHpf/7+qcLqVgYGBqbEv3/+zAOxsOL0H3/WICQAQ3EQA8NPRoQUAwMLMoe5Ko6Z4TGyCJzNbr7xz98/iZjO5UqSrlv358+fR8lccMVwRtwfEHibBRcAMxB2PpnOsPscWIzWBAC6AFAsMgob5AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 3\n",
      "Predicted: 9\n",
      "torch.Size([63700, 784]) torch.Size([63700, 10]) torch.Size([63700, 10])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    x = x.to(device, non_blocking=True)\n",
    "    y = y.to(device, non_blocking=True)\n",
    "\n",
    "    Display.image_Display(x[1])\n",
    "    print(\"Label:\", y[1].item())\n",
    "\n",
    "    bounds = (0.0, 255.0)\n",
    "    Scaling1 = Scaling(x, bounds)\n",
    "    Classifier1 = Classifier(10).to(device, non_blocking=True)\n",
    "    net = NN().to(device, non_blocking=True)\n",
    "\n",
    "    x_scaled = Scaling1(x)\n",
    "    y_encoded = Classifier1(y)\n",
    "\n",
    "    yHAT = net(x_scaled)\n",
    "    loss = net.loss_fn(yHAT, y)\n",
    "    print(\"CrossEntropy Loss:\", loss.item())\n",
    "\n",
    "    x_inverse = Scaling1.inverse(x_scaled)\n",
    "    y_declassified = Classifier1.inverse(y_encoded)\n",
    "    yHAT_declassified = Classifier1.inverse(yHAT)\n",
    "\n",
    "    Display.image_Display(x_inverse[1])\n",
    "    print(\"Actual:\", y_declassified[1].item())\n",
    "    print(\"Predicted:\", yHAT_declassified[1].item())\n",
    "\n",
    "    print(x_scaled.shape, y_encoded.shape, yHAT.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fdf6e3b4ca6f8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:05:27.108871Z",
     "start_time": "2025-07-15T17:05:27.080685Z"
    }
   },
   "outputs": [],
   "source": [
    "class UltraFastTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        loss_fn: nn.Module,\n",
    "        optimizer_cls=torch.optim.Adam,\n",
    "        lr=1e-3,\n",
    "        max_epochs=50,\n",
    "        clip_grad_norm=1.0,\n",
    "        use_amp=True,\n",
    "        use_tqdm=False,\n",
    "        save_path=None\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer_cls(model.parameters(), lr=lr)\n",
    "        self.max_epochs = max_epochs\n",
    "        self.clip_grad_norm = clip_grad_norm\n",
    "        self.use_amp = use_amp\n",
    "        self.save_path = save_path\n",
    "        self.use_tqdm = use_tqdm\n",
    "\n",
    "        self.scaler_amp = GradScaler(enabled=use_amp)\n",
    "        self.loss_history = []\n",
    "\n",
    "    def _prefetch_loader(self, loader):\n",
    "        for x, y in loader:\n",
    "            yield x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        self.model.train()\n",
    "\n",
    "        x_sample, _ = next(iter(train_loader))\n",
    "        scaler = Scaling(x_sample.to(device))\n",
    "\n",
    "        for epoch in range(1, self.max_epochs + 1):\n",
    "            start = time.perf_counter()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            iterable = self._prefetch_loader(train_loader)\n",
    "            if self.use_tqdm:\n",
    "                iterable = tqdm(iterable, desc=f\"Epoch {epoch}\", leave=False)\n",
    "\n",
    "            for x, y in iterable:\n",
    "                x = scaler(x)\n",
    "\n",
    "                self.optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                with autocast(device_type=device.type, enabled=self.use_amp):\n",
    "                    y_pred = self.model(x)\n",
    "                    loss = self.loss_fn(y_pred, y)\n",
    "\n",
    "                if epoch % 1 == 0:  # Show on every epoch\n",
    "                    visualize_activations(self.model.activations, epoch)\n",
    "\n",
    "                \n",
    "                self.scaler_amp.scale(loss).backward()\n",
    "\n",
    "                if self.clip_grad_norm:\n",
    "                    self.scaler_amp.unscale_(self.optimizer)\n",
    "                    nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_grad_norm)\n",
    "\n",
    "                self.scaler_amp.step(self.optimizer)\n",
    "                self.scaler_amp.update()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            self.loss_history.append(avg_loss)\n",
    "\n",
    "            elapsed = time.perf_counter() - start\n",
    "            print(f\"Epoch {epoch:03d} | Loss: {avg_loss:.4f} | Time: {elapsed:.2f}s\")\n",
    "\n",
    "        if self.save_path:\n",
    "            torch.save(self.model.state_dict(), self.save_path)\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        scaler = Scaling(next(iter(test_loader))[0].to(device))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x, y in self._prefetch_loader(test_loader):\n",
    "                x = scaler(x)\n",
    "                pred = self.model(x).argmax(dim=1)\n",
    "                correct += (pred == y.view(-1)).sum().item()\n",
    "                total += y.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
    "        return acc\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_history)\n",
    "        plt.title(\"Loss Curve\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e64e84209dd5b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T17:08:07.032409Z",
     "start_time": "2025-07-15T17:05:27.140546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss: 2.3002 | Time: 26.16s\n",
      "Epoch 002 | Loss: 2.2955 | Time: 26.95s\n",
      "Epoch 003 | Loss: 2.2905 | Time: 44.97s\n",
      "Epoch 004 | Loss: 2.2851 | Time: 30.04s\n",
      "Epoch 005 | Loss: 2.2794 | Time: 31.79s\n",
      "Epoch 006 | Loss: 2.2734 | Time: 38.39s\n",
      "Epoch 007 | Loss: 2.2669 | Time: 31.63s\n",
      "Epoch 008 | Loss: 2.2600 | Time: 31.07s\n",
      "Epoch 009 | Loss: 2.2529 | Time: 29.04s\n",
      "Epoch 010 | Loss: 2.2455 | Time: 29.83s\n",
      "Epoch 011 | Loss: 2.2380 | Time: 29.86s\n",
      "Epoch 012 | Loss: 2.2302 | Time: 30.65s\n",
      "Epoch 013 | Loss: 2.2226 | Time: 30.09s\n",
      "Epoch 014 | Loss: 2.2149 | Time: 29.91s\n",
      "Epoch 015 | Loss: 2.2077 | Time: 31.03s\n",
      "Epoch 016 | Loss: 2.2005 | Time: 31.86s\n",
      "Epoch 017 | Loss: 2.1935 | Time: 31.79s\n",
      "Epoch 018 | Loss: 2.1865 | Time: 31.05s\n",
      "Epoch 019 | Loss: 2.1796 | Time: 30.42s\n",
      "Epoch 020 | Loss: 2.1728 | Time: 29.87s\n",
      "Epoch 021 | Loss: 2.1664 | Time: 30.68s\n",
      "Epoch 022 | Loss: 2.1601 | Time: 30.50s\n",
      "Epoch 023 | Loss: 2.1538 | Time: 30.13s\n",
      "Epoch 024 | Loss: 2.1476 | Time: 29.92s\n",
      "Epoch 025 | Loss: 2.1415 | Time: 30.51s\n",
      "Epoch 026 | Loss: 2.1356 | Time: 31.66s\n",
      "Epoch 027 | Loss: 2.1296 | Time: 31.21s\n",
      "Epoch 028 | Loss: 2.1238 | Time: 31.07s\n",
      "Epoch 029 | Loss: 2.1179 | Time: 29.64s\n",
      "Epoch 030 | Loss: 2.1119 | Time: 29.59s\n",
      "Epoch 031 | Loss: 2.1059 | Time: 30.36s\n",
      "Epoch 032 | Loss: 2.0998 | Time: 31.15s\n",
      "Epoch 033 | Loss: 2.0935 | Time: 29.82s\n",
      "Epoch 034 | Loss: 2.0873 | Time: 29.92s\n",
      "Epoch 035 | Loss: 2.0808 | Time: 30.83s\n",
      "Epoch 036 | Loss: 2.0741 | Time: 32.45s\n",
      "Epoch 037 | Loss: 2.0671 | Time: 35.20s\n",
      "Epoch 038 | Loss: 2.0600 | Time: 31.46s\n",
      "Epoch 039 | Loss: 2.0524 | Time: 30.38s\n",
      "Epoch 040 | Loss: 2.0446 | Time: 31.05s\n",
      "Epoch 041 | Loss: 2.0365 | Time: 31.94s\n",
      "Epoch 042 | Loss: 2.0280 | Time: 31.67s\n",
      "Epoch 043 | Loss: 2.0194 | Time: 31.02s\n",
      "Epoch 044 | Loss: 2.0108 | Time: 31.27s\n",
      "Epoch 045 | Loss: 2.0022 | Time: 33.07s\n",
      "Epoch 046 | Loss: 1.9935 | Time: 32.55s\n",
      "Epoch 047 | Loss: 1.9841 | Time: 33.72s\n",
      "Epoch 048 | Loss: 1.9745 | Time: 30.11s\n",
      "Epoch 049 | Loss: 1.9650 | Time: 28.96s\n",
      "Epoch 050 | Loss: 1.9551 | Time: 31.26s\n",
      "Epoch 051 | Loss: 1.9457 | Time: 30.55s\n",
      "Epoch 052 | Loss: 1.9367 | Time: 29.36s\n",
      "Epoch 053 | Loss: 1.9280 | Time: 30.26s\n",
      "Epoch 054 | Loss: 1.9199 | Time: 50.41s\n",
      "Epoch 055 | Loss: 1.9119 | Time: 29.14s\n",
      "Epoch 056 | Loss: 1.9041 | Time: 30.42s\n",
      "Epoch 057 | Loss: 1.8969 | Time: 28.83s\n",
      "Epoch 058 | Loss: 1.8900 | Time: 26.38s\n",
      "Epoch 059 | Loss: 1.8834 | Time: 29.07s\n",
      "Epoch 060 | Loss: 1.8770 | Time: 25.86s\n",
      "Epoch 061 | Loss: 1.8711 | Time: 26.39s\n",
      "Epoch 062 | Loss: 1.8654 | Time: 27.12s\n",
      "Epoch 063 | Loss: 1.8601 | Time: 26.28s\n",
      "Epoch 064 | Loss: 1.8550 | Time: 26.32s\n",
      "Epoch 065 | Loss: 1.8502 | Time: 28.00s\n",
      "Epoch 066 | Loss: 1.8457 | Time: 24.38s\n",
      "Epoch 067 | Loss: 1.8414 | Time: 27.19s\n",
      "Epoch 068 | Loss: 1.8373 | Time: 26.47s\n",
      "Epoch 069 | Loss: 1.8333 | Time: 26.25s\n",
      "Epoch 070 | Loss: 1.8297 | Time: 26.27s\n",
      "Epoch 071 | Loss: 1.8261 | Time: 26.24s\n",
      "Epoch 072 | Loss: 1.8227 | Time: 26.23s\n",
      "Epoch 073 | Loss: 1.8195 | Time: 26.90s\n",
      "Epoch 074 | Loss: 1.8165 | Time: 25.81s\n",
      "Epoch 075 | Loss: 1.8134 | Time: 26.57s\n",
      "Epoch 076 | Loss: 1.8106 | Time: 26.41s\n",
      "Epoch 077 | Loss: 1.8079 | Time: 27.15s\n",
      "Epoch 078 | Loss: 1.8053 | Time: 26.01s\n",
      "Epoch 079 | Loss: 1.8028 | Time: 25193.82s\n",
      "Epoch 080 | Loss: 1.8005 | Time: 53.00s\n",
      "Epoch 081 | Loss: 1.7982 | Time: 36.13s\n",
      "Epoch 082 | Loss: 1.7960 | Time: 30.59s\n",
      "Epoch 083 | Loss: 1.7939 | Time: 31.22s\n",
      "Epoch 084 | Loss: 1.7919 | Time: 34.07s\n",
      "Epoch 085 | Loss: 1.7900 | Time: 33.18s\n",
      "Epoch 086 | Loss: 1.7881 | Time: 35.52s\n",
      "Epoch 087 | Loss: 1.7864 | Time: 33.02s\n",
      "Epoch 088 | Loss: 1.7847 | Time: 49.73s\n",
      "Epoch 089 | Loss: 1.7830 | Time: 58.51s\n",
      "Epoch 090 | Loss: 1.7814 | Time: 37.40s\n",
      "Epoch 091 | Loss: 1.7799 | Time: 33.28s\n",
      "Epoch 092 | Loss: 1.7785 | Time: 32.43s\n",
      "Epoch 093 | Loss: 1.7770 | Time: 32.16s\n",
      "Epoch 094 | Loss: 1.7756 | Time: 32.52s\n",
      "Epoch 095 | Loss: 1.7743 | Time: 40.33s\n",
      "Epoch 096 | Loss: 1.7730 | Time: 46.80s\n",
      "Epoch 097 | Loss: 1.7717 | Time: 30.36s\n",
      "Epoch 098 | Loss: 1.7706 | Time: 24.87s\n"
     ]
    }
   ],
   "source": [
    "model = NN()\n",
    "trainer = UltraFastTrainer(model, nn.CrossEntropyLoss(), max_epochs=100, use_amp=True)\n",
    "\n",
    "trainer.train(train_loader)\n",
    "trainer.evaluate(test_loader)\n",
    "trainer.plot_loss()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
